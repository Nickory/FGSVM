{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdeac896-5463-482f-9c10-3189d5495c4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] 训练集形状: X=(9527, 16), y=(9527,)\n",
      "[DEBUG] 训练集 y 分布: Counter({np.int64(-1): 6817, np.int64(1): 2710})\n",
      "[DEBUG] 测试集 y 分布: Counter({np.int64(-1): 2923, np.int64(1): 1161})\n",
      "测试集标签集合: {np.int64(1), np.int64(-1)}\n",
      "\n",
      "正在进行特征标准化 (StandardScaler)...\n",
      "开始训练普通 SVM (SVC with RBF kernel)...\n",
      "[LibSVM].\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 1456\n",
      "obj = -785.017927, rho = -0.086582\n",
      "nSV = 925, nBSV = 860\n",
      "Total nSV = 925\n",
      "训练完成，用时: 0.33 秒\n",
      "预测完成，用时: 0.21 秒\n",
      "\n",
      "[DEBUG] 测试集预测值分布: Counter({np.int64(-1): 2894, np.int64(1): 1190})\n",
      "[DEBUG] 正类预测数量 (1): 1190\n",
      "[DEBUG] 负类预测数量 (-1): 2894\n",
      "\n",
      "混淆矩阵:\n",
      " [[2854   69]\n",
      " [  40 1121]]\n",
      "TP=1121, FP=69, TN=2854, FN=40\n",
      "\n",
      "最终评估结果: [0.9733104799216454, 0.9420168067226891, 0.9655469422911284, np.float64(0.023605884365378037), 0.9536367503190132]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def evaluation_para(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates and returns evaluation metrics for a machine learning model.\n",
    "    Args:\n",
    "        y_true (list): A list of ground truth labels.\n",
    "        y_pred (list): A list of predicted labels from the model.\n",
    "    Returns:\n",
    "        list: A list containing the evaluation metrics in the following order:\n",
    "              [accuracy, precision, recall, fpr, f1].\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='binary', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='binary')\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "    metrics = [accuracy, precision, recall, fpr, f1]\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def getdata():\n",
    "    train = np.load('dataset/train.npy')\n",
    "    test = np.load('dataset/test.npy')\n",
    "    \n",
    "    # 使用全量数据（与你之前一致）\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    X_test = test[:, :-1]\n",
    "    y_test = test[:, -1]\n",
    "    \n",
    "    # 标签转换：0 → -1, 1 → 1（与 FGSVM 一致）\n",
    "    y_train = np.where(y_train == 0, -1, 1).astype(int)\n",
    "    y_test = np.where(y_test == 0, -1, 1).astype(int)\n",
    "    \n",
    "    print(f\"[DEBUG] 训练集形状: X={X_train.shape}, y={y_train.shape}\")\n",
    "    print(f\"[DEBUG] 训练集 y 分布: {Counter(y_train)}\")\n",
    "    print(f\"[DEBUG] 测试集 y 分布: {Counter(y_test)}\")\n",
    "    print(\"测试集标签集合:\", set(y_test))\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X_train, y_train, X_test, y_test = getdata()\n",
    "    \n",
    "    # 特征标准化（SVM 对尺度非常敏感，必须做）\n",
    "    print(\"\\n正在进行特征标准化 (StandardScaler)...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print(\"开始训练普通 SVM (SVC with RBF kernel)...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model = SVC(\n",
    "        C=1.0,                    # 建议从 1.0 开始，避免过拟合\n",
    "        kernel='rbf',\n",
    "        gamma='scale',            # 自动计算 gamma = 1 / (n_features * X.var())，最稳\n",
    "        # gamma=0.01,             # 如果想手动调，可取消注释，从 0.001~0.1 试\n",
    "        class_weight='balanced',  # 自动处理不平衡，给少数类更高权重\n",
    "        tol=1e-3,\n",
    "        max_iter=-1,              # 无限制迭代，直到收敛\n",
    "        random_state=42,\n",
    "        verbose=True              # 显示 libsvm 训练过程\n",
    "    )\n",
    "    \n",
    "    # 训练\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"训练完成，用时: {train_time:.2f} 秒\")\n",
    "    \n",
    "    # 预测\n",
    "    start_time = time.time()\n",
    "    pred = model.predict(X_test_scaled)\n",
    "    predict_time = time.time() - start_time\n",
    "    print(f\"预测完成，用时: {predict_time:.2f} 秒\")\n",
    "    \n",
    "    # Debug 打印（与你原代码风格一致）\n",
    "    print(\"\\n[DEBUG] 测试集预测值分布:\", Counter(pred))\n",
    "    print(\"[DEBUG] 正类预测数量 (1):\", np.sum(pred == 1))\n",
    "    print(\"[DEBUG] 负类预测数量 (-1):\", np.sum(pred == -1))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    print(\"\\n混淆矩阵:\\n\", cm)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "    \n",
    "    result = evaluation_para(y_test, pred)\n",
    "    print(\"\\n最终评估结果:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a8a319b-b9ba-451a-a836-d5466e52113f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] 训练集形状: X=(9527, 16), y=(9527,)\n",
      "[DEBUG] 训练集 y 分布: Counter({np.int64(-1): 6817, np.int64(1): 2710})\n",
      "[DEBUG] 测试集 y 分布: Counter({np.int64(-1): 2923, np.int64(1): 1161})\n",
      "测试集标签集合: {np.int64(1), np.int64(-1)}\n",
      "\n",
      "正在进行特征标准化 (StandardScaler)...\n",
      "开始训练 FGSVM...\n",
      "Granulating the training data...\n",
      "Granulation finished, starting training.\n",
      "开始训练 15 个基 SVM 模型（每个模型独立训练）...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training base SVMs: 100%|████████████████████████████████████████| 15/15 [00:01<00:00, 11.33model/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有基 SVM 训练完成！\n",
      "训练完成，用时: 1.38 秒\n",
      "预测完成，用时: 0.06 秒\n",
      "\n",
      "[DEBUG] 测试集预测值分布: Counter({np.int64(-1): 2956, np.int64(1): 1128})\n",
      "[DEBUG] 正类预测数量 (1): 1128\n",
      "[DEBUG] 负类预测数量 (-1): 2956\n",
      "\n",
      "混淆矩阵:\n",
      " [[2881   42]\n",
      " [  75 1086]]\n",
      "TP=1086, FP=42, TN=2881, FN=75\n",
      "\n",
      "最终评估结果: [0.9713516160626836, 0.9627659574468085, 0.9354005167958657, np.float64(0.014368799178925761), 0.9488859764089121]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from granular import FGSVM  # 假设你的 FGSVM 类在 granular.py 中\n",
    "\n",
    "\n",
    "def evaluation_para(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates and returns evaluation metrics for a machine learning model.\n",
    "    Args:\n",
    "        y_true (list): A list of ground truth labels.\n",
    "        y_pred (list): A list of predicted labels from the model.\n",
    "    Returns:\n",
    "        list: A list containing the evaluation metrics in the following order:\n",
    "              [accuracy, precision, recall, fpr, f1].\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='binary', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='binary')\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "    metrics = [accuracy, precision, recall, fpr, f1]\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def getdata():\n",
    "    train = np.load('dataset/train.npy')\n",
    "    test = np.load('dataset/test.npy')\n",
    "    \n",
    "    # 使用全量数据\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    X_test = test[:, :-1]\n",
    "    y_test = test[:, -1]\n",
    "    \n",
    "    # 标签转换：0 → -1, 1 → 1\n",
    "    y_train = np.where(y_train == 0, -1, 1).astype(int)\n",
    "    y_test = np.where(y_test == 0, -1, 1).astype(int)\n",
    "    \n",
    "    print(f\"[DEBUG] 训练集形状: X={X_train.shape}, y={y_train.shape}\")\n",
    "    print(f\"[DEBUG] 训练集 y 分布: {Counter(y_train)}\")\n",
    "    print(f\"[DEBUG] 测试集 y 分布: {Counter(y_test)}\")\n",
    "    print(\"测试集标签集合:\", set(y_test))\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X_train, y_train, X_test, y_test = getdata()\n",
    "    \n",
    "    # ★★★ 新增：特征标准化（强烈推荐！）\n",
    "    print(\"\\n正在进行特征标准化 (StandardScaler)...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print(\"开始训练 FGSVM...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model = FGSVM(\n",
    "        C=10.0,          # 增大惩罚\n",
    "        kernel='rbf',\n",
    "        degree=3,\n",
    "        gamma=4.9,     # ★★★ 强烈建议先调小！原 4.9 太大了，试 0.01~0.1\n",
    "                        # 如果想自动：可以自定义实现 gamma='scale'（1 / (n_features * X.var())）\n",
    "        beta=0.929,\n",
    "        tol=1e-3,\n",
    "        max_iter=100    # 增加迭代次数，避免早停\n",
    "    )\n",
    "    \n",
    "    # 使用标准化后的数据训练\n",
    "    model.fit(X_train_scaled, y_train, reference_n=15)  # 建议增大参考点数\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"训练完成，用时: {train_time:.2f} 秒\")\n",
    "    \n",
    "    # 预测（也用标准化后的测试集）\n",
    "    start_time = time.time()\n",
    "    pred = model.predict(X_test_scaled)\n",
    "    predict_time = time.time() - start_time\n",
    "    print(f\"预测完成，用时: {predict_time:.2f} 秒\")\n",
    "    \n",
    "    # Debug 打印\n",
    "    print(\"\\n[DEBUG] 测试集预测值分布:\", Counter(pred))\n",
    "    print(\"[DEBUG] 正类预测数量 (1):\", np.sum(pred == 1))\n",
    "    print(\"[DEBUG] 负类预测数量 (-1):\", np.sum(pred == -1))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    print(\"\\n混淆矩阵:\\n\", cm)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "    \n",
    "    result = evaluation_para(y_test, pred)\n",
    "    print(\"\\n最终评估结果:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4b01f1f-d17f-4b57-a583-4d851a57c05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] 训练集形状: X=(9527, 16), y=(9527,)\n",
      "[DEBUG] 训练集 y 分布: Counter({np.int64(-1): 6817, np.int64(1): 2710})\n",
      "[DEBUG] 测试集 y 分布: Counter({np.int64(-1): 2923, np.int64(1): 1161})\n",
      "测试集标签集合: {np.int64(1), np.int64(-1)}\n",
      "\n",
      "正在进行特征归一化/标准化...\n",
      "当前使用：RobustScaler（推荐用于网络流量数据中的极端值）\n",
      "开始训练 FGSVM...\n",
      "Granulating the training data...\n",
      "Granulation finished, starting training.\n",
      "开始训练 15 个基 SVM 模型（每个模型独立训练）...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training base SVMs: 100%|████████████████████████████████████████| 15/15 [00:01<00:00, 13.99model/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有基 SVM 训练完成！\n",
      "训练完成，用时: 1.13 秒\n",
      "预测完成，用时: 0.05 秒\n",
      "\n",
      "[DEBUG] 测试集预测值分布: Counter({np.int64(-1): 2962, np.int64(1): 1122})\n",
      "[DEBUG] 正类预测数量 (1): 1122\n",
      "[DEBUG] 负类预测数量 (-1): 2962\n",
      "\n",
      "混淆矩阵:\n",
      " [[2889   34]\n",
      " [  73 1088]]\n",
      "TP=1088, FP=34, TN=2889, FN=73\n",
      "\n",
      "最终评估结果: [0.9738001958863859, 0.9696969696969697, 0.9371231696813093, np.float64(0.011631885049606569), 0.953131844064827]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from granular import FGSVM  # 假设你的 FGSVM 类在 granular.py 中\n",
    "\n",
    "\n",
    "def evaluation_para(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates and returns evaluation metrics for a machine learning model.\n",
    "    Args:\n",
    "        y_true (list): A list of ground truth labels.\n",
    "        y_pred (list): A list of predicted labels from the model.\n",
    "    Returns:\n",
    "        list: A list containing the evaluation metrics in the following order:\n",
    "              [accuracy, precision, recall, fpr, f1].\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='binary', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='binary')\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "    metrics = [accuracy, precision, recall, fpr, f1]\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def getdata():\n",
    "    train = np.load('dataset/train.npy')\n",
    "    test = np.load('dataset/test.npy')\n",
    "    \n",
    "    # 使用全量数据\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    X_test = test[:, :-1]\n",
    "    y_test = test[:, -1]\n",
    "    \n",
    "    # 标签转换：0 → -1, 1 → 1\n",
    "    y_train = np.where(y_train == 0, -1, 1).astype(int)\n",
    "    y_test = np.where(y_test == 0, -1, 1).astype(int)\n",
    "    \n",
    "    print(f\"[DEBUG] 训练集形状: X={X_train.shape}, y={y_train.shape}\")\n",
    "    print(f\"[DEBUG] 训练集 y 分布: {Counter(y_train)}\")\n",
    "    print(f\"[DEBUG] 测试集 y 分布: {Counter(y_test)}\")\n",
    "    print(\"测试集标签集合:\", set(y_test))\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X_train, y_train, X_test, y_test = getdata()\n",
    "    \n",
    "    # ★★★ 升级版数据归一化：优先使用 RobustScaler（对离群点更鲁棒）\n",
    "    print(\"\\n正在进行特征归一化/标准化...\")\n",
    "    print(\"当前使用：RobustScaler（推荐用于网络流量数据中的极端值）\")\n",
    "    \n",
    "    # 选项1：RobustScaler（当前推荐）\n",
    "    scaler = RobustScaler()\n",
    "    \n",
    "    # 选项2：StandardScaler（之前用过的，注释掉即可切换）\n",
    "    # scaler = StandardScaler()\n",
    "    \n",
    "    # 选项3：MinMaxScaler（缩到 [0,1]，有时对 RBF 核友好）\n",
    "    # scaler = MinMaxScaler()\n",
    "    \n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "    \n",
    "    print(\"开始训练 FGSVM...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model = FGSVM(\n",
    "        C=10.0,          # 参数不变\n",
    "        kernel='rbf',\n",
    "        degree=3,\n",
    "        gamma=4.9,       # 参数不变（但注意：gamma 仍偏大，后续建议调小）\n",
    "        beta=0.929,      # 参数不变\n",
    "        tol=1e-3,\n",
    "        max_iter=100     # 参数不变\n",
    "    )\n",
    "    \n",
    "    # 使用归一化/标准化后的数据训练\n",
    "    model.fit(X_train_scaled, y_train, reference_n=15)\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"训练完成，用时: {train_time:.2f} 秒\")\n",
    "    \n",
    "    # 预测（也用处理后的测试集）\n",
    "    start_time = time.time()\n",
    "    pred = model.predict(X_test_scaled)\n",
    "    predict_time = time.time() - start_time\n",
    "    print(f\"预测完成，用时: {predict_time:.2f} 秒\")\n",
    "    \n",
    "    # Debug 打印\n",
    "    print(\"\\n[DEBUG] 测试集预测值分布:\", Counter(pred))\n",
    "    print(\"[DEBUG] 正类预测数量 (1):\", np.sum(pred == 1))\n",
    "    print(\"[DEBUG] 负类预测数量 (-1):\", np.sum(pred == -1))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    print(\"\\n混淆矩阵:\\n\", cm)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "    \n",
    "    result = evaluation_para(y_test, pred)\n",
    "    print(\"\\n最终评估结果:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e82ba4-23fc-44eb-9ab1-4fa70cc519c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
